{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"avito_train.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3995803, 13) 0.0688212106553\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attrs</th>\n",
       "      <th>price</th>\n",
       "      <th>is_proved</th>\n",
       "      <th>is_blocked</th>\n",
       "      <th>phones_cnt</th>\n",
       "      <th>emails_cnt</th>\n",
       "      <th>urls_cnt</th>\n",
       "      <th>close_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000010</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили с пробегом</td>\n",
       "      <td>Toyota Sera, 1991</td>\n",
       "      <td>Новая оригинальная линзованая оптика на ксенон...</td>\n",
       "      <td>{\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...</td>\n",
       "      <td>150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000025</td>\n",
       "      <td>Услуги</td>\n",
       "      <td>Предложения услуг</td>\n",
       "      <td>Монтаж кровли</td>\n",
       "      <td>Выполняем  монтаж кровли фальцевой ^p Тел:8@@P...</td>\n",
       "      <td>{\"Вид услуги\":\"Ремонт, строительство\"}</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000094</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>Костюм Steilmann</td>\n",
       "      <td>Юбка и топ из панбархата. Под топ  трикотажная...</td>\n",
       "      <td>{\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000101</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили с пробегом</td>\n",
       "      <td>Ford Focus, 2011</td>\n",
       "      <td>Автомобиль в отличном техническом состоянии, в...</td>\n",
       "      <td>{\"Марка\":\"Ford\", \"Модель\":\"Focus\", \"Год выпуск...</td>\n",
       "      <td>365000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000132</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>Турбина 3.0 Bar</td>\n",
       "      <td>Продам турбину на двигатель V-6 . V-8 и мощнее...</td>\n",
       "      <td>{\"Вид товара\":\"Запчасти\", \"Тип товара\":\"Для ав...</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     itemid     category                subcategory              title  \\\n",
       "0  10000010    Транспорт      Автомобили с пробегом  Toyota Sera, 1991   \n",
       "1  10000025       Услуги          Предложения услуг      Монтаж кровли   \n",
       "2  10000094  Личные вещи  Одежда, обувь, аксессуары   Костюм Steilmann   \n",
       "3  10000101    Транспорт      Автомобили с пробегом   Ford Focus, 2011   \n",
       "4  10000132    Транспорт      Запчасти и аксессуары    Турбина 3.0 Bar   \n",
       "\n",
       "                                         description  \\\n",
       "0  Новая оригинальная линзованая оптика на ксенон...   \n",
       "1  Выполняем  монтаж кровли фальцевой ^p Тел:8@@P...   \n",
       "2  Юбка и топ из панбархата. Под топ  трикотажная...   \n",
       "3  Автомобиль в отличном техническом состоянии, в...   \n",
       "4  Продам турбину на двигатель V-6 . V-8 и мощнее...   \n",
       "\n",
       "                                               attrs   price  is_proved  \\\n",
       "0  {\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...  150000        NaN   \n",
       "1             {\"Вид услуги\":\"Ремонт, строительство\"}       0        NaN   \n",
       "2  {\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...    1500        NaN   \n",
       "3  {\"Марка\":\"Ford\", \"Модель\":\"Focus\", \"Год выпуск...  365000        NaN   \n",
       "4  {\"Вид товара\":\"Запчасти\", \"Тип товара\":\"Для ав...    5000        NaN   \n",
       "\n",
       "   is_blocked  phones_cnt  emails_cnt  urls_cnt  close_hours  \n",
       "0           0           0           0         0         0.03  \n",
       "1           0           1           0         0        22.38  \n",
       "2           0           0           0         0         0.41  \n",
       "3           0           0           0         0         8.87  \n",
       "4           0           0           0         0        11.82  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df.shape, df.is_blocked.mean()\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio 0.0688212106553\n",
      "Count: 3995803\n"
     ]
    }
   ],
   "source": [
    "print \"Blocked ratio\",df.is_blocked.mean()\n",
    "print \"Count:\",len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274996, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.is_blocked == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Балансируем выборку рандомным downsample-ом негативных объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio: 0.47825724005\n",
      "Count: 574996\n"
     ]
    }
   ],
   "source": [
    "#downsample\n",
    "df = df[df.is_blocked == 1].append(df[df.is_blocked == 0].sample(300000, random_state=42))\n",
    "df.sort_values('itemid', inplace=True)\n",
    "\n",
    "print \"Blocked ratio:\",df.is_blocked.mean()\n",
    "print \"Count:\",len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизируем заголовки и описания, одновременно заменяя все слова на их нормальные формы при помощи pymorphy2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pymorphy2\n",
    "\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 14min 57s, sys: 16.7 s, total: 1h 15min 13s\n",
      "Wall time: 1h 14min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Нормализацию можно распараллелить, но не было критично\n",
    "def normalize(s):\n",
    "    if type(s) is float:\n",
    "        return s\n",
    "    return ' '.join([morph.parse(t)[0].normal_form for t in tokenizer.tokenize(unicode(s.decode('utf-8')))])\n",
    "\n",
    "df.loc[:,'description'] = df.description.apply(normalize)\n",
    "df.loc[:,'title'] = df.title.apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составляем словарь токенов, присваиваем им id-шники"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter,defaultdict\n",
    "\n",
    "#Dictionary of tokens\n",
    "token_counts = Counter()\n",
    "\n",
    "#All texts\n",
    "all_texts = np.hstack([df.description.values,df.title.values])\n",
    "\n",
    "\n",
    "#Compute token frequencies\n",
    "for s in all_texts:\n",
    "    if type(s) is not unicode:\n",
    "        continue\n",
    "#     s = s.decode('utf8').lower()\n",
    "    tokens = tokenizer.tokenize(s)\n",
    "    for token in tokens:\n",
    "        token_counts[token] +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаляем слишком редкие токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAFkCAYAAAD7dJuCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxXAiSZKqYjiRJElVMZxIkqSq/H84kvLujJZKHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f36bbc70350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Word frequency distribution, just for kicks\n",
    "_=plt.hist(token_counts.values(),range=[0,50],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Select only the tokens that had at least 10 occurences in the corpora.\n",
    "#Use token_counts.\n",
    "min_count = 20\n",
    "tokens = [token for token, count in token_counts.iteritems() if count >= min_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В финальном решении использовалось значение min_count=10, кол-во токенов получалось около 50к"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {t:i+1 for i,t in enumerate(tokens)}\n",
    "null_token = \"NULL\"\n",
    "token_to_id[null_token] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tokens: 33594\n"
     ]
    }
   ],
   "source": [
    "print \"# Tokens:\",len(token_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заменяем тексты на вектора id-шников фиксированной размерности, используя 0-padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(strings, token_to_id, max_len=150):\n",
    "    token_matrix = []\n",
    "    for s in strings:\n",
    "        if type(s) is not unicode:\n",
    "            token_matrix.append([0]*max_len)\n",
    "            continue\n",
    "#         s = s.decode('utf8').lower()\n",
    "        tokens = tokenizer.tokenize(s)\n",
    "        token_ids = map(lambda token: token_to_id.get(token,0), tokens)[:max_len]\n",
    "        token_ids += [0]*(max_len - len(token_ids))\n",
    "        token_matrix.append(token_ids)\n",
    "\n",
    "    return np.array(token_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desc_tokens = vectorize(df.description.values,token_to_id,max_len = 150)\n",
    "title_tokens = vectorize(df.title.values,token_to_id,max_len = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (574996, 15)\n",
      "дизайн интерьер комплексный отделка -> [32534  9764   987 22411     0     0     0     0     0     0] ...\n",
      "поездка на таможня печать в паспорт -> [ 8737 11283  8695 17992 27710  9031     0     0     0     0] ...\n",
      "комната 13 м² в 2 к 5 5 эт -> [19997 30811 19575 27710  2406 23197 16380 16380 10072     0] ...\n"
     ]
    }
   ],
   "source": [
    "print \"Размер матрицы:\",title_tokens.shape\n",
    "for title, tokens in zip(df.title.values[:3],title_tokens[:3]):\n",
    "    print title,'->', tokens[:10],'...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка порядковых и категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All numeric features\n",
    "df_numerical_features = df[[\"phones_cnt\",\"emails_cnt\",\"urls_cnt\",\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#One-hot-encoded category and subcategory\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categories = []\n",
    "data_cat_subcat = df[[\"category\",\"subcategory\"]].values\n",
    "\n",
    "categories = [{\"category\":category_name, \"subcategory\":subcategory_name}\\\n",
    "              for category_name, subcategory_name in data_cat_subcat]\n",
    "\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "cat_one_hot = vectorizer.fit_transform(categories)\n",
    "cat_one_hot = pd.DataFrame(cat_one_hot,columns=vectorizer.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_non_text = pd.merge(\n",
    "    df_numerical_features,cat_one_hot,on = np.arange(len(cat_one_hot))\n",
    ")\n",
    "del df_non_text[\"key_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Делим выборку на обучающую и валидационную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Target variable - whether or not sample contains prohibited material\n",
    "target = df.is_blocked.values.astype('int32')\n",
    "#Preprocessed titles\n",
    "title_tokens = title_tokens.astype('int32')\n",
    "#Preprocessed tokens\n",
    "desc_tokens = desc_tokens.astype('int32')\n",
    "#Non-sequences\n",
    "df_non_text = df_non_text.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split into training and test set.\n",
    "#Select test set items that have item_ids strictly above that of training set\n",
    "\n",
    "TEST_SIZE = 0.1\n",
    "split_value = int(df.shape[0] * (1. - TEST_SIZE))\n",
    "\n",
    "title_tr, title_ts = title_tokens[:split_value], title_tokens[split_value:]\n",
    "desc_tr, desc_ts = desc_tokens[:split_value], desc_tokens[split_value:]\n",
    "nontext_tr, nontext_ts = df_non_text[:split_value], df_non_text[split_value:]\n",
    "target_tr, target_ts = target[:split_value], target[split_value:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that classes balance maintains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47803461282792525, 0.48026086956521741)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tr.mean(), target_ts.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохраняем предобработанные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading saved data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "save_prepared_data = False #save\n",
    "read_prepared_data = True #load\n",
    "\n",
    "#but not both at once\n",
    "assert not (save_prepared_data and read_prepared_data)\n",
    "\n",
    "if save_prepared_data:\n",
    "    print \"Saving preprocessed data (may take up to 3 minutes)\"\n",
    "\n",
    "    import pickle\n",
    "    data_tuple = title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts\n",
    "    with open(\"preprocessed_data_norm_min20.pcl\",'w') as fout:\n",
    "        pickle.dump(data_tuple,fout)\n",
    "    with open(\"token_to_id_norm_min20.pcl\",'w') as fout:\n",
    "        pickle.dump(token_to_id,fout)\n",
    "\n",
    "    print \"готово\"\n",
    "    \n",
    "elif read_prepared_data:\n",
    "    print \"Reading saved data...\"\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    with open(\"preprocessed_data_norm_min10.pcl\",'r') as fin:\n",
    "        data_tuple = pickle.load(fin)\n",
    "    title_tr,title_ts,desc_tr,desc_ts,nontext_tr,nontext_ts,target_tr,target_ts = data_tuple\n",
    "    with open(\"token_to_id_norm_min10.pcl\",'r') as fin:\n",
    "        token_to_id = pickle.load(fin)\n",
    "        \n",
    "    #Re-importing libraries to allow staring noteboook from here\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "   \n",
    "    print \"done\"        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаем сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import lasagne\n",
    "from theano import tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 inputs and a refere output\n",
    "title_token_ids = T.matrix(\"title_token_ids\",dtype='int32')\n",
    "desc_token_ids = T.matrix(\"desc_token_ids\",dtype='int32')\n",
    "categories = T.matrix(\"categories\",dtype='float32')\n",
    "target_y = T.ivector(\"is_blocked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_inp = lasagne.layers.InputLayer((None,title_tr.shape[1]),input_var=title_token_ids)\n",
    "descr_inp = lasagne.layers.InputLayer((None,desc_tr.shape[1]),input_var=desc_token_ids)\n",
    "cat_inp = lasagne.layers.InputLayer((None,nontext_tr.shape[1]), input_var=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_EMBED = 256\n",
    "N_HIDDEN_DESCR = 256\n",
    "N_HIDDEN_TITLE = 256\n",
    "GRAD_CLIP = 100\n",
    "N_DENSE_CAT = 64\n",
    "\n",
    "# Descriptions\n",
    "descr_nn = lasagne.layers.EmbeddingLayer(descr_inp, input_size=len(token_to_id)+1, output_size=N_EMBED)\n",
    "descr_nn = lasagne.layers.LSTMLayer(descr_nn, N_HIDDEN_DESCR, grad_clipping=GRAD_CLIP, \n",
    "                                    nonlinearity=lasagne.nonlinearities.tanh, only_return_final=True)\n",
    "\n",
    "# Titles\n",
    "title_nn = lasagne.layers.EmbeddingLayer(title_inp, input_size=len(token_to_id)+1, output_size=N_EMBED)\n",
    "title_nn = lasagne.layers.LSTMLayer(title_nn, N_HIDDEN_TITLE, grad_clipping=GRAD_CLIP, \n",
    "                                    nonlinearity=lasagne.nonlinearities.tanh, only_return_final=True)\n",
    "\n",
    "# Non-sequences\n",
    "cat_nn = lasagne.layers.DenseLayer(cat_inp, N_DENSE_CAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_DENSE = 256\n",
    "P_DROPOUT = 0.5\n",
    "\n",
    "nn = lasagne.layers.ConcatLayer([descr_nn, title_nn, cat_nn])\n",
    "\n",
    "nn = lasagne.layers.DenseLayer(nn, N_DENSE)\n",
    "nn = lasagne.layers.DropoutLayer(nn, p=P_DROPOUT)\n",
    "nn = lasagne.layers.DenseLayer(nn, 1, nonlinearity=lasagne.nonlinearities.linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All trainable params\n",
    "weights = lasagne.layers.get_all_params(nn,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Simple NN prediction\n",
    "prediction = lasagne.layers.get_output(nn)[:,0]\n",
    "\n",
    "DELTA = 1.\n",
    "#Hinge loss\n",
    "loss = lasagne.objectives.binary_hinge_loss(prediction,target_y,delta = DELTA).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Weight optimization step\n",
    "LR = 0.001\n",
    "updates = lasagne.updates.adam(loss, weights, learning_rate=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#deterministic version\n",
    "det_prediction = lasagne.layers.get_output(nn,deterministic=True)[:,0]\n",
    "\n",
    "#equivalent loss function\n",
    "det_loss = lasagne.objectives.binary_hinge_loss(det_prediction,target_y,delta = DELTA).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.5 s, sys: 288 ms, total: 18.7 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],[loss,prediction],updates = updates)\n",
    "eval_fun = theano.function([desc_token_ids,title_token_ids,categories,target_y],[det_loss,det_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#average precision at K\n",
    "from oracle import APatK, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Out good old minibatch iterator now supports arbitrary amount of arrays (X,y,z)\n",
    "def iterate_minibatches(*arrays,**kwargs):\n",
    "    batchsize=kwargs.get(\"batchsize\",100)\n",
    "    shuffle = kwargs.get(\"shuffle\",True)\n",
    "    \n",
    "    if shuffle:\n",
    "        indices = np.arange(len(arrays[0]))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(arrays[0]) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield [arr[excerpt] for arr in arrays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train:\n",
      "\tloss: 9978.11415355\n",
      "\tacc: 0.623861386139\n",
      "\tauc: 0.656580392665\n",
      "\tap@k: 0.0389121582806\n",
      "Val:\n",
      "\tloss: 3298.10400504\n",
      "\tacc: 0.557722772277\n",
      "\tauc: 0.567579572165\n",
      "\tap@k: 0.479663165654\n",
      "Epoch: 1\n",
      "Train:\n",
      "\tloss: 3693.60662268\n",
      "\tacc: 0.673564356436\n",
      "\tauc: 0.702795028716\n",
      "\tap@k: 0.0651140921868\n",
      "Val:\n",
      "\tloss: 1886.47200105\n",
      "\tacc: 0.710792079208\n",
      "\tauc: 0.68720931009\n",
      "\tap@k: 0.837130445955\n",
      "Epoch: 2\n",
      "Train:\n",
      "\tloss: 5541.93536943\n",
      "\tacc: 0.714554455446\n",
      "\tauc: 0.738042712648\n",
      "\tap@k: 0.035607828999\n",
      "Val:\n",
      "\tloss: 4504.06496233\n",
      "\tacc: 0.612079207921\n",
      "\tauc: 0.644785265935\n",
      "\tap@k: 0.796911256178\n",
      "Epoch: 3\n",
      "Train:\n",
      "\tloss: 2965.18614598\n",
      "\tacc: 0.676732673267\n",
      "\tauc: 0.70298491787\n",
      "\tap@k: 0.0921708543678\n",
      "Val:\n",
      "\tloss: 6617.08863805\n",
      "\tacc: 0.596435643564\n",
      "\tauc: 0.582960238375\n",
      "\tap@k: 0.870612513649\n",
      "Epoch: 4\n",
      "Train:\n",
      "\tloss: 2212.75352871\n",
      "\tacc: 0.688613861386\n",
      "\tauc: 0.726946369096\n",
      "\tap@k: 0.0697623838052\n",
      "Val:\n",
      "\tloss: 6869.69722099\n",
      "\tacc: 0.600396039604\n",
      "\tauc: 0.626036987817\n",
      "\tap@k: 0.768867047641\n",
      "Epoch: 5\n",
      "Train:\n",
      "\tloss: 4818.48453586\n",
      "\tacc: 0.68900990099\n",
      "\tauc: 0.720987131769\n",
      "\tap@k: 0.0699273552217\n",
      "Val:\n",
      "\tloss: 5500.59173308\n",
      "\tacc: 0.574653465347\n",
      "\tauc: 0.613536065541\n",
      "\tap@k: 0.883513929077\n",
      "Epoch: 6\n",
      "Train:\n",
      "\tloss: 6106.25870101\n",
      "\tacc: 0.65\n",
      "\tauc: 0.639573392436\n",
      "\tap@k: 0.129189329115\n",
      "Val:\n",
      "\tloss: 2379.45101641\n",
      "\tacc: 0.608217821782\n",
      "\tauc: 0.614372371319\n",
      "\tap@k: 0.848692400442\n",
      "Epoch: 7\n",
      "Train:\n",
      "\tloss: 1850.82437624\n",
      "\tacc: 0.705643564356\n",
      "\tauc: 0.726310583417\n",
      "\tap@k: 0.00987980314932\n",
      "Val:\n",
      "\tloss: 3703.40911905\n",
      "\tacc: 0.638514851485\n",
      "\tauc: 0.625524189765\n",
      "\tap@k: 0.818204301213\n",
      "Epoch: 8\n",
      "Train:\n",
      "\tloss: 1246.94716398\n",
      "\tacc: 0.741386138614\n",
      "\tauc: 0.791963300119\n",
      "\tap@k: 0.184083517992\n",
      "Val:\n",
      "\tloss: 966.351912338\n",
      "\tacc: 0.625940594059\n",
      "\tauc: 0.662803844358\n",
      "\tap@k: 0.810116062469\n",
      "Epoch: 9\n",
      "Train:\n",
      "\tloss: 618.485460448\n",
      "\tacc: 0.735148514851\n",
      "\tauc: 0.768972292484\n",
      "\tap@k: 0.0206305148347\n",
      "Val:\n",
      "\tloss: 2169.05572863\n",
      "\tacc: 0.668613861386\n",
      "\tauc: 0.661418524559\n",
      "\tap@k: 0.83144314993\n",
      "Epoch: 10\n",
      "Train:\n",
      "\tloss: 3399.32253133\n",
      "\tacc: 0.692673267327\n",
      "\tauc: 0.698087772701\n",
      "\tap@k: 0.0244482740841\n",
      "Val:\n",
      "\tloss: 1243.31273403\n",
      "\tacc: 0.690594059406\n",
      "\tauc: 0.677887788208\n",
      "\tap@k: 0.903906055451\n",
      "Epoch: 11\n",
      "Train:\n",
      "\tloss: 2059.63852152\n",
      "\tacc: 0.725445544554\n",
      "\tauc: 0.741090006295\n",
      "\tap@k: 0.02654321897\n",
      "Val:\n",
      "\tloss: 277.629727219\n",
      "\tacc: 0.710099009901\n",
      "\tauc: 0.722303202987\n",
      "\tap@k: 0.879698049247\n",
      "Epoch: 12\n",
      "Train:\n",
      "\tloss: 1356.40876536\n",
      "\tacc: 0.765841584158\n",
      "\tauc: 0.783528782047\n",
      "\tap@k: 0.0506006836644\n",
      "Val:\n",
      "\tloss: 2334.13265897\n",
      "\tacc: 0.690792079208\n",
      "\tauc: 0.676408802919\n",
      "\tap@k: 0.809545659803\n",
      "Epoch: 13\n",
      "Train:\n",
      "\tloss: 1666.52499697\n",
      "\tacc: 0.706831683168\n",
      "\tauc: 0.710179289366\n",
      "\tap@k: 0.0874243676774\n",
      "Val:\n",
      "\tloss: 470.132568022\n",
      "\tacc: 0.702574257426\n",
      "\tauc: 0.709382489636\n",
      "\tap@k: 0.92262615027\n",
      "Epoch: 14\n",
      "Train:\n",
      "\tloss: 792.230401138\n",
      "\tacc: 0.744554455446\n",
      "\tauc: 0.772292329792\n",
      "\tap@k: 0.0649507014727\n",
      "Val:\n",
      "\tloss: 902.696431752\n",
      "\tacc: 0.665544554455\n",
      "\tauc: 0.646024117242\n",
      "\tap@k: 0.820950644959\n",
      "Epoch: 15\n",
      "Train:\n",
      "\tloss: 1301.92766784\n",
      "\tacc: 0.732475247525\n",
      "\tauc: 0.768099693366\n",
      "\tap@k: 0.0911158491623\n",
      "Val:\n",
      "\tloss: 713.368577322\n",
      "\tacc: 0.696336633663\n",
      "\tauc: 0.692299206773\n",
      "\tap@k: 0.817762552557\n",
      "Epoch: 16\n",
      "Train:\n",
      "\tloss: 1207.87173189\n",
      "\tacc: 0.711485148515\n",
      "\tauc: 0.71047935545\n",
      "\tap@k: 0.0716832772718\n",
      "Val:\n",
      "\tloss: 474.522545411\n",
      "\tacc: 0.702475247525\n",
      "\tauc: 0.708422097116\n",
      "\tap@k: 0.8555206186\n",
      "Epoch: 17\n",
      "Train:\n",
      "\tloss: 91.9459476879\n",
      "\tacc: 0.751584158416\n",
      "\tauc: 0.787594117121\n",
      "\tap@k: 0.124500222378\n",
      "Val:\n",
      "\tloss: 341.984727507\n",
      "\tacc: 0.624653465347\n",
      "\tauc: 0.644973226653\n",
      "\tap@k: 0.893555765856\n",
      "Epoch: 18\n",
      "Train:\n",
      "\tloss: 88.3231469384\n",
      "\tacc: 0.771089108911\n",
      "\tauc: 0.790050123823\n",
      "\tap@k: 0.0658078157793\n",
      "Val:\n",
      "\tloss: 230.066327908\n",
      "\tacc: 0.696930693069\n",
      "\tauc: 0.706928361738\n",
      "\tap@k: 0.813560514368\n",
      "Epoch: 19\n",
      "Train:\n",
      "\tloss: 120.089213526\n",
      "\tacc: 0.780495049505\n",
      "\tauc: 0.793719936235\n",
      "\tap@k: 0.0403417901075\n",
      "Val:\n",
      "\tloss: 131.459858186\n",
      "\tacc: 0.71396039604\n",
      "\tauc: 0.720284901177\n",
      "\tap@k: 0.794712889211\n",
      "Epoch: 20\n",
      "Train:\n",
      "\tloss: 136.843633038\n",
      "\tacc: 0.781386138614\n",
      "\tauc: 0.789127768103\n",
      "\tap@k: 0.0488161782289\n",
      "Val:\n",
      "\tloss: 92.58648713\n",
      "\tacc: 0.737524752475\n",
      "\tauc: 0.73936023898\n",
      "\tap@k: 0.787681514223\n",
      "Epoch: 21\n",
      "Train:\n",
      "\tloss: 82.3739382394\n",
      "\tacc: 0.797425742574\n",
      "\tauc: 0.819792089653\n",
      "\tap@k: 0.0522746971115\n",
      "Val:\n",
      "\tloss: 74.1915706839\n",
      "\tacc: 0.722376237624\n",
      "\tauc: 0.729662427709\n",
      "\tap@k: 0.796525763949\n",
      "Epoch: 22\n",
      "Train:\n",
      "\tloss: 293.556997439\n",
      "\tacc: 0.766930693069\n",
      "\tauc: 0.782950790716\n",
      "\tap@k: 0.0161779952836\n",
      "Val:\n",
      "\tloss: 43.3253770803\n",
      "\tacc: 0.704158415842\n",
      "\tauc: 0.729155227547\n",
      "\tap@k: 0.860703865833\n",
      "Epoch: 23\n",
      "Train:\n",
      "\tloss: 67.2242594815\n",
      "\tacc: 0.779504950495\n",
      "\tauc: 0.811898861196\n",
      "\tap@k: 0.109744307299\n",
      "Val:\n",
      "\tloss: 10.6005402854\n",
      "\tacc: 0.750693069307\n",
      "\tauc: 0.774504043458\n",
      "\tap@k: 0.825333919915\n",
      "Epoch: 24\n",
      "Train:\n",
      "\tloss: 24.2733869476\n",
      "\tacc: 0.782178217822\n",
      "\tauc: 0.811696502075\n",
      "\tap@k: 0.0585245341048\n",
      "Val:\n",
      "\tloss: 13.7164030496\n",
      "\tacc: 0.728118811881\n",
      "\tauc: 0.758095461042\n",
      "\tap@k: 0.760840928758\n",
      "Epoch: 25\n",
      "Train:\n",
      "\tloss: 17.040973504\n",
      "\tacc: 0.804653465347\n",
      "\tauc: 0.851042413522\n",
      "\tap@k: 0.364464043781\n",
      "Val:\n",
      "\tloss: 0.568609415129\n",
      "\tacc: 0.766633663366\n",
      "\tauc: 0.847453424794\n",
      "\tap@k: 0.839660384355\n",
      "Epoch: 26\n",
      "Train:\n",
      "\tloss: 0.495142157101\n",
      "\tacc: 0.802079207921\n",
      "\tauc: 0.84458914281\n",
      "\tap@k: 0.973526685844\n",
      "Val:\n",
      "\tloss: 0.518439117168\n",
      "\tacc: 0.756633663366\n",
      "\tauc: 0.839265153846\n",
      "\tap@k: 0.856049866759\n",
      "Epoch: 27\n",
      "Train:\n",
      "\tloss: 0.788219714205\n",
      "\tacc: 0.809900990099\n",
      "\tauc: 0.852528227855\n",
      "\tap@k: 0.970282919097\n",
      "Val:\n",
      "\tloss: 0.500145394023\n",
      "\tacc: 0.761683168317\n",
      "\tauc: 0.850744897323\n",
      "\tap@k: 0.819022431208\n",
      "Epoch: 28\n",
      "Train:\n",
      "\tloss: 103.779800124\n",
      "\tacc: 0.808712871287\n",
      "\tauc: 0.857289190308\n",
      "\tap@k: 0.961994198735\n",
      "Val:\n",
      "\tloss: 0.504917450943\n",
      "\tacc: 0.765247524752\n",
      "\tauc: 0.856185450409\n",
      "\tap@k: 0.831063581784\n",
      "Epoch: 29\n",
      "Train:\n",
      "\tloss: 0.476120392629\n",
      "\tacc: 0.808910891089\n",
      "\tauc: 0.856120528261\n",
      "\tap@k: 0.973815740837\n",
      "Val:\n",
      "\tloss: 0.543714899177\n",
      "\tacc: 0.752376237624\n",
      "\tauc: 0.846281422933\n",
      "\tap@k: 0.818267733852\n",
      "Epoch: 30\n",
      "Train:\n",
      "\tloss: 0.467118738773\n",
      "\tacc: 0.808514851485\n",
      "\tauc: 0.859470273073\n",
      "\tap@k: 0.97483545599\n",
      "Val:\n",
      "\tloss: 0.51050129813\n",
      "\tacc: 0.760396039604\n",
      "\tauc: 0.851066279712\n",
      "\tap@k: 0.83172047059\n",
      "Epoch: 31\n",
      "Train:\n",
      "\tloss: 0.455687186559\n",
      "\tacc: 0.808514851485\n",
      "\tauc: 0.865748311979\n",
      "\tap@k: 0.966597323712\n",
      "Val:\n",
      "\tloss: 0.511817558426\n",
      "\tacc: 0.758415841584\n",
      "\tauc: 0.854737695308\n",
      "\tap@k: 0.861376581132\n",
      "Epoch: 32\n",
      "Train:\n",
      "\tloss: 0.47501267478\n",
      "\tacc: 0.799603960396\n",
      "\tauc: 0.860842767757\n",
      "\tap@k: 0.978670236682\n",
      "Val:\n",
      "\tloss: 0.510857139721\n",
      "\tacc: 0.759108910891\n",
      "\tauc: 0.849563775728\n",
      "\tap@k: 0.826670260507\n",
      "Epoch: 33\n",
      "Train:\n",
      "\tloss: 0.444109894046\n",
      "\tacc: 0.814653465347\n",
      "\tauc: 0.87455434325\n",
      "\tap@k: 0.969215406215\n",
      "Val:\n",
      "\tloss: 0.518426619851\n",
      "\tacc: 0.755346534653\n",
      "\tauc: 0.84593473338\n",
      "\tap@k: 0.899149051963\n",
      "Epoch: 34\n",
      "Train:\n",
      "\tloss: 0.460819810532\n",
      "\tacc: 0.805643564356\n",
      "\tauc: 0.867729351604\n",
      "\tap@k: 0.961352050084\n",
      "Val:\n",
      "\tloss: 0.520880015087\n",
      "\tacc: 0.75495049505\n",
      "\tauc: 0.84654400077\n",
      "\tap@k: 0.857170001061\n",
      "Epoch: 35\n",
      "Train:\n",
      "\tloss: 0.672013986198\n",
      "\tacc: 0.81099009901\n",
      "\tauc: 0.873988447181\n",
      "\tap@k: 0.779973598411\n",
      "Val:\n",
      "\tloss: 0.501876500396\n",
      "\tacc: 0.763762376238\n",
      "\tauc: 0.862890780063\n",
      "\tap@k: 0.882348397649\n",
      "Epoch: 36\n",
      "Train:\n",
      "\tloss: 0.431738968165\n",
      "\tacc: 0.814851485149\n",
      "\tauc: 0.884384511828\n",
      "\tap@k: 0.97348862457\n",
      "Val:\n",
      "\tloss: 0.489254771358\n",
      "\tacc: 0.76702970297\n",
      "\tauc: 0.867918999922\n",
      "\tap@k: 0.891250390055\n",
      "Epoch: 37\n",
      "Train:\n",
      "\tloss: 0.437769633533\n",
      "\tacc: 0.812079207921\n",
      "\tauc: 0.881884764635\n",
      "\tap@k: 0.977221630546\n",
      "Val:\n",
      "\tloss: 0.469732051508\n",
      "\tacc: 0.775841584158\n",
      "\tauc: 0.869674874606\n",
      "\tap@k: 0.859659379015\n",
      "Epoch: 38\n",
      "Train:\n",
      "\tloss: 0.407386883574\n",
      "\tacc: 0.825544554455\n",
      "\tauc: 0.895335903031\n",
      "\tap@k: 0.940623327943\n",
      "Val:\n",
      "\tloss: 0.51047483136\n",
      "\tacc: 0.756633663366\n",
      "\tauc: 0.863027119205\n",
      "\tap@k: 0.868945881951\n",
      "Epoch: 39\n",
      "Train:\n",
      "\tloss: 0.410916925642\n",
      "\tacc: 0.825742574257\n",
      "\tauc: 0.896486002268\n",
      "\tap@k: 0.96649292378\n",
      "Val:\n",
      "\tloss: 0.459132328801\n",
      "\tacc: 0.782475247525\n",
      "\tauc: 0.874445472345\n",
      "\tap@k: 0.908903419226\n",
      "Epoch: 40\n",
      "Train:\n",
      "\tloss: 0.384001659252\n",
      "\tacc: 0.841485148515\n",
      "\tauc: 0.906837105878\n",
      "\tap@k: 0.95910760552\n",
      "Val:\n",
      "\tloss: 0.43464181034\n",
      "\tacc: 0.810891089109\n",
      "\tauc: 0.883717850611\n",
      "\tap@k: 0.916304881436\n",
      "Epoch: 41\n",
      "Train:\n",
      "\tloss: 0.377948698474\n",
      "\tacc: 0.845643564356\n",
      "\tauc: 0.911493579806\n",
      "\tap@k: 0.98587227058\n",
      "Val:\n",
      "\tloss: 0.42279014877\n",
      "\tacc: 0.821188118812\n",
      "\tauc: 0.893724054731\n",
      "\tap@k: 0.887684161744\n",
      "Epoch: 42\n",
      "Train:\n",
      "\tloss: 0.344990479439\n",
      "\tacc: 0.85495049505\n",
      "\tauc: 0.926465671812\n",
      "\tap@k: 0.958999554121\n",
      "Val:\n",
      "\tloss: 0.393158844863\n",
      "\tacc: 0.832673267327\n",
      "\tauc: 0.908624960692\n",
      "\tap@k: 0.931465167549\n",
      "Epoch: 43\n",
      "Train:\n",
      "\tloss: 0.349647112787\n",
      "\tacc: 0.852178217822\n",
      "\tauc: 0.925007818021\n",
      "\tap@k: 0.97395433794\n",
      "Val:\n",
      "\tloss: 0.372212004335\n",
      "\tacc: 0.839108910891\n",
      "\tauc: 0.91064215034\n",
      "\tap@k: 0.898645178713\n",
      "Epoch: 44\n",
      "Train:\n",
      "\tloss: 0.315824153216\n",
      "\tacc: 0.867326732673\n",
      "\tauc: 0.934271114537\n",
      "\tap@k: 0.978919226217\n",
      "Val:\n",
      "\tloss: 0.351049160983\n",
      "\tacc: 0.844158415842\n",
      "\tauc: 0.920329782838\n",
      "\tap@k: 0.90723472237\n",
      "Epoch: 45\n",
      "Train:\n",
      "\tloss: 0.299180595536\n",
      "\tacc: 0.871782178218\n",
      "\tauc: 0.940074623563\n",
      "\tap@k: 0.995627206507\n",
      "Val:\n",
      "\tloss: 0.341501365902\n",
      "\tacc: 0.844554455446\n",
      "\tauc: 0.929870468342\n",
      "\tap@k: 0.966299279992\n",
      "Epoch: 46\n",
      "Train:\n",
      "\tloss: 0.288531824542\n",
      "\tacc: 0.875346534653\n",
      "\tauc: 0.944370065292\n",
      "\tap@k: 0.958641982904\n",
      "Val:\n",
      "\tloss: 0.313319673525\n",
      "\tacc: 0.856831683168\n",
      "\tauc: 0.936306881865\n",
      "\tap@k: 0.925227055093\n",
      "Epoch: 47\n",
      "Train:\n",
      "\tloss: 0.287496952959\n",
      "\tacc: 0.88\n",
      "\tauc: 0.944592865368\n",
      "\tap@k: 0.980010449906\n",
      "Val:\n",
      "\tloss: 0.319434055143\n",
      "\tacc: 0.851386138614\n",
      "\tauc: 0.934814209669\n",
      "\tap@k: 0.960583352992\n",
      "Epoch: 48\n",
      "Train:\n",
      "\tloss: 0.286880222668\n",
      "\tacc: 0.892475247525\n",
      "\tauc: 0.944456496404\n",
      "\tap@k: 0.960420876663\n",
      "Val:\n",
      "\tloss: 0.2980209582\n",
      "\tacc: 0.878415841584\n",
      "\tauc: 0.939260544717\n",
      "\tap@k: 0.938744253372\n",
      "Epoch: 49\n",
      "Train:\n",
      "\tloss: 0.265970352455\n",
      "\tacc: 0.90396039604\n",
      "\tauc: 0.950998131399\n",
      "\tap@k: 0.983168426709\n",
      "Val:\n",
      "\tloss: 0.306320972414\n",
      "\tacc: 0.884257425743\n",
      "\tauc: 0.941163368936\n",
      "\tap@k: 0.943489805704\n",
      "Epoch: 50\n",
      "Train:\n",
      "\tloss: 0.245137874946\n",
      "\tacc: 0.913663366337\n",
      "\tauc: 0.95628929652\n",
      "\tap@k: 0.967645963226\n",
      "Val:\n",
      "\tloss: 0.277333636473\n",
      "\tacc: 0.892376237624\n",
      "\tauc: 0.944557556128\n",
      "\tap@k: 0.96785119\n",
      "Epoch: 51\n",
      "Train:\n",
      "\tloss: 0.244580250116\n",
      "\tacc: 0.912673267327\n",
      "\tauc: 0.954530122343\n",
      "\tap@k: 0.99223674773\n",
      "Val:\n",
      "\tloss: 0.270938403824\n",
      "\tacc: 0.897425742574\n",
      "\tauc: 0.947752940346\n",
      "\tap@k: 0.985620670673\n",
      "Epoch: 52\n",
      "Train:\n",
      "\tloss: 0.230650012412\n",
      "\tacc: 0.915643564356\n",
      "\tauc: 0.956881209899\n",
      "\tap@k: 0.992550679356\n",
      "Val:\n",
      "\tloss: 0.274891084887\n",
      "\tacc: 0.88900990099\n",
      "\tauc: 0.943705472432\n",
      "\tap@k: 0.976535930649\n",
      "Epoch: 53\n",
      "Train:\n",
      "\tloss: 0.370225956284\n",
      "\tacc: 0.916336633663\n",
      "\tauc: 0.956963997968\n",
      "\tap@k: 0.988554970747\n",
      "Val:\n",
      "\tloss: 0.247307736226\n",
      "\tacc: 0.9\n",
      "\tauc: 0.948668615093\n",
      "\tap@k: 0.973943959343\n",
      "Epoch: 54\n",
      "Train:\n",
      "\tloss: 0.220389251345\n",
      "\tacc: 0.918217821782\n",
      "\tauc: 0.958632382646\n",
      "\tap@k: 0.97165634664\n",
      "Val:\n",
      "\tloss: 0.259405967876\n",
      "\tacc: 0.893762376238\n",
      "\tauc: 0.945617149826\n",
      "\tap@k: 0.967236338255\n",
      "Epoch: 55\n",
      "Train:\n",
      "\tloss: 0.221699664121\n",
      "\tacc: 0.915247524752\n",
      "\tauc: 0.958552889392\n",
      "\tap@k: 0.98818270508\n",
      "Val:\n",
      "\tloss: 0.25601550523\n",
      "\tacc: 0.89702970297\n",
      "\tauc: 0.947249283076\n",
      "\tap@k: 0.949625204222\n",
      "Epoch: 56\n",
      "Train:\n",
      "\tloss: 0.213149343708\n",
      "\tacc: 0.920594059406\n",
      "\tauc: 0.959383049835\n",
      "\tap@k: 0.978983718516\n",
      "Val:\n",
      "\tloss: 0.248986223644\n",
      "\tacc: 0.894851485149\n",
      "\tauc: 0.950312266393\n",
      "\tap@k: 0.969245401778\n",
      "Epoch: 57\n",
      "Train:\n",
      "\tloss: 0.205528686478\n",
      "\tacc: 0.92702970297\n",
      "\tauc: 0.95937569327\n",
      "\tap@k: 0.99832958103\n",
      "Val:\n",
      "\tloss: 0.219200726594\n",
      "\tacc: 0.908712871287\n",
      "\tauc: 0.952076720613\n",
      "\tap@k: 0.959408849441\n",
      "Epoch: 58\n",
      "Train:\n",
      "\tloss: 0.202434109753\n",
      "\tacc: 0.924851485149\n",
      "\tauc: 0.959959274622\n",
      "\tap@k: 0.980663117106\n",
      "Val:\n",
      "\tloss: 0.226673322593\n",
      "\tacc: 0.905148514851\n",
      "\tauc: 0.953167551169\n",
      "\tap@k: 0.978608400548\n",
      "Epoch: 59\n",
      "Train:\n",
      "\tloss: 0.201277568919\n",
      "\tacc: 0.926336633663\n",
      "\tauc: 0.960413600629\n",
      "\tap@k: 0.995756027456\n",
      "Val:\n",
      "\tloss: 0.239340471346\n",
      "\tacc: 0.898217821782\n",
      "\tauc: 0.948772891887\n",
      "\tap@k: 0.964243185645\n",
      "Epoch: 60\n",
      "Train:\n",
      "\tloss: 0.204657590851\n",
      "\tacc: 0.921584158416\n",
      "\tauc: 0.961880556567\n",
      "\tap@k: 0.999339708192\n",
      "Val:\n",
      "\tloss: 0.254604324299\n",
      "\tacc: 0.896633663366\n",
      "\tauc: 0.950026003265\n",
      "\tap@k: 0.962035449346\n",
      "Epoch: 61\n",
      "Train:\n",
      "\tloss: 0.197891611085\n",
      "\tacc: 0.926435643564\n",
      "\tauc: 0.963221959158\n",
      "\tap@k: 0.987649500795\n",
      "Val:\n",
      "\tloss: 0.226687281723\n",
      "\tacc: 0.904752475248\n",
      "\tauc: 0.953639234618\n",
      "\tap@k: 0.960582898946\n",
      "Epoch: 62\n",
      "Train:\n",
      "\tloss: 0.21808823606\n",
      "\tacc: 0.924653465347\n",
      "\tauc: 0.961426455578\n",
      "\tap@k: 0.96148865441\n",
      "Val:\n",
      "\tloss: 0.233776485958\n",
      "\tacc: 0.901881188119\n",
      "\tauc: 0.953131313155\n",
      "\tap@k: 0.982076279618\n",
      "Epoch: 63\n",
      "Train:\n",
      "\tloss: 0.195500862606\n",
      "\tacc: 0.92702970297\n",
      "\tauc: 0.964667747673\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.23258523882\n",
      "\tacc: 0.901287128713\n",
      "\tauc: 0.957195052426\n",
      "\tap@k: 0.988340794905\n",
      "Epoch: 64\n",
      "Train:\n",
      "\tloss: 0.202025873956\n",
      "\tacc: 0.92495049505\n",
      "\tauc: 0.9614635095\n",
      "\tap@k: 0.977216596851\n",
      "Val:\n",
      "\tloss: 0.223353443059\n",
      "\tacc: 0.901386138614\n",
      "\tauc: 0.958793337218\n",
      "\tap@k: 0.989661229656\n",
      "Epoch: 65\n",
      "Train:\n",
      "\tloss: 0.207313711034\n",
      "\tacc: 0.919801980198\n",
      "\tauc: 0.960715539861\n",
      "\tap@k: 0.9852410142\n",
      "Val:\n",
      "\tloss: 0.227420200059\n",
      "\tacc: 0.90297029703\n",
      "\tauc: 0.957212903664\n",
      "\tap@k: 0.97562795584\n",
      "Epoch: 66\n",
      "Train:\n",
      "\tloss: 0.188701823439\n",
      "\tacc: 0.929306930693\n",
      "\tauc: 0.965580091587\n",
      "\tap@k: 0.97808451802\n",
      "Val:\n",
      "\tloss: 0.230884660593\n",
      "\tacc: 0.898613861386\n",
      "\tauc: 0.955945550132\n",
      "\tap@k: 0.993384794561\n",
      "Epoch: 67\n",
      "Train:\n",
      "\tloss: 0.17977432656\n",
      "\tacc: 0.929900990099\n",
      "\tauc: 0.966630909516\n",
      "\tap@k: 0.999968692399\n",
      "Val:\n",
      "\tloss: 0.231796876523\n",
      "\tacc: 0.901287128713\n",
      "\tauc: 0.954786133946\n",
      "\tap@k: 0.974284712025\n",
      "Epoch: 68\n",
      "Train:\n",
      "\tloss: 0.191523952322\n",
      "\tacc: 0.927821782178\n",
      "\tauc: 0.960741245358\n",
      "\tap@k: 0.979461610407\n",
      "Val:\n",
      "\tloss: 0.223160422891\n",
      "\tacc: 0.906534653465\n",
      "\tauc: 0.960532183559\n",
      "\tap@k: 0.964958796004\n",
      "Epoch: 69\n",
      "Train:\n",
      "\tloss: 0.18400157199\n",
      "\tacc: 0.927920792079\n",
      "\tauc: 0.965710545681\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.233210010899\n",
      "\tacc: 0.902574257426\n",
      "\tauc: 0.961778374645\n",
      "\tap@k: 0.980533517381\n",
      "Epoch: 70\n",
      "Train:\n",
      "\tloss: 0.181766374813\n",
      "\tacc: 0.928118811881\n",
      "\tauc: 0.967056613197\n",
      "\tap@k: 0.997027489398\n",
      "Val:\n",
      "\tloss: 0.242080405495\n",
      "\tacc: 0.900495049505\n",
      "\tauc: 0.961621784174\n",
      "\tap@k: 0.975119553991\n",
      "Epoch: 71\n",
      "Train:\n",
      "\tloss: 0.217083286507\n",
      "\tacc: 0.912376237624\n",
      "\tauc: 0.961287637036\n",
      "\tap@k: 0.988715527959\n",
      "Val:\n",
      "\tloss: 0.21884814674\n",
      "\tacc: 0.904752475248\n",
      "\tauc: 0.964227789187\n",
      "\tap@k: 0.977830993318\n",
      "Epoch: 72\n",
      "Train:\n",
      "\tloss: 0.185116441449\n",
      "\tacc: 0.926534653465\n",
      "\tauc: 0.968590763585\n",
      "\tap@k: 0.989815379512\n",
      "Val:\n",
      "\tloss: 0.23328237498\n",
      "\tacc: 0.895841584158\n",
      "\tauc: 0.961091828743\n",
      "\tap@k: 0.982814681053\n",
      "Epoch: 73\n",
      "Train:\n",
      "\tloss: 0.182489466437\n",
      "\tacc: 0.927326732673\n",
      "\tauc: 0.968096646609\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.227855129528\n",
      "\tacc: 0.898415841584\n",
      "\tauc: 0.961793365357\n",
      "\tap@k: 0.975841026037\n",
      "Epoch: 74\n",
      "Train:\n",
      "\tloss: 0.17966756196\n",
      "\tacc: 0.929405940594\n",
      "\tauc: 0.969388972031\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.228151160754\n",
      "\tacc: 0.905841584158\n",
      "\tauc: 0.966204231581\n",
      "\tap@k: 0.977853413256\n",
      "Epoch: 75\n",
      "Train:\n",
      "\tloss: 0.172845460693\n",
      "\tacc: 0.935445544554\n",
      "\tauc: 0.973484543481\n",
      "\tap@k: 0.996543170673\n",
      "Val:\n",
      "\tloss: 0.213924796332\n",
      "\tacc: 0.907128712871\n",
      "\tauc: 0.967417363952\n",
      "\tap@k: 0.974317963701\n",
      "Epoch: 76\n",
      "Train:\n",
      "\tloss: 0.16866201885\n",
      "\tacc: 0.934059405941\n",
      "\tauc: 0.973538454245\n",
      "\tap@k: 0.997157626152\n",
      "Val:\n",
      "\tloss: 0.207089921164\n",
      "\tacc: 0.909801980198\n",
      "\tauc: 0.969060996565\n",
      "\tap@k: 0.986322709881\n",
      "Epoch: 77\n",
      "Train:\n",
      "\tloss: 0.175690880235\n",
      "\tacc: 0.932673267327\n",
      "\tauc: 0.970707418035\n",
      "\tap@k: 0.982485458497\n",
      "Val:\n",
      "\tloss: 0.199634247534\n",
      "\tacc: 0.915643564356\n",
      "\tauc: 0.97288371277\n",
      "\tap@k: 0.979486482954\n",
      "Epoch: 78\n",
      "Train:\n",
      "\tloss: 0.162472053192\n",
      "\tacc: 0.935445544554\n",
      "\tauc: 0.975984904595\n",
      "\tap@k: 0.991693354018\n",
      "Val:\n",
      "\tloss: 0.212103786113\n",
      "\tacc: 0.90702970297\n",
      "\tauc: 0.965866395822\n",
      "\tap@k: 0.993644997365\n",
      "Epoch: 79\n",
      "Train:\n",
      "\tloss: 0.181050211225\n",
      "\tacc: 0.929405940594\n",
      "\tauc: 0.967079223567\n",
      "\tap@k: 0.99575014036\n",
      "Val:\n",
      "\tloss: 0.209083935797\n",
      "\tacc: 0.909405940594\n",
      "\tauc: 0.968716271272\n",
      "\tap@k: 0.992912388036\n",
      "Epoch: 80\n",
      "Train:\n",
      "\tloss: 0.175822768514\n",
      "\tacc: 0.932277227723\n",
      "\tauc: 0.969082634638\n",
      "\tap@k: 0.995085151537\n",
      "Val:\n",
      "\tloss: 0.211710685987\n",
      "\tacc: 0.901782178218\n",
      "\tauc: 0.967197379101\n",
      "\tap@k: 0.993904793409\n",
      "Epoch: 81\n",
      "Train:\n",
      "\tloss: 0.172131708267\n",
      "\tacc: 0.932772277228\n",
      "\tauc: 0.9716716367\n",
      "\tap@k: 0.996529654524\n",
      "Val:\n",
      "\tloss: 0.195048406742\n",
      "\tacc: 0.912376237624\n",
      "\tauc: 0.971730079767\n",
      "\tap@k: 0.995366564881\n",
      "Epoch: 82\n",
      "Train:\n",
      "\tloss: 0.175837159399\n",
      "\tacc: 0.929603960396\n",
      "\tauc: 0.971619021243\n",
      "\tap@k: 0.998744214293\n",
      "Val:\n",
      "\tloss: 0.207780178766\n",
      "\tacc: 0.908712871287\n",
      "\tauc: 0.970464158052\n",
      "\tap@k: 0.979619705082\n",
      "Epoch: 83\n",
      "Train:\n",
      "\tloss: 0.177836116172\n",
      "\tacc: 0.933564356436\n",
      "\tauc: 0.973554410817\n",
      "\tap@k: 0.989458777303\n",
      "Val:\n",
      "\tloss: 0.196990014025\n",
      "\tacc: 0.917227722772\n",
      "\tauc: 0.971998459973\n",
      "\tap@k: 0.981851426644\n",
      "Epoch: 84\n",
      "Train:\n",
      "\tloss: 0.202225479194\n",
      "\tacc: 0.932871287129\n",
      "\tauc: 0.971136259878\n",
      "\tap@k: 0.994941725776\n",
      "Val:\n",
      "\tloss: 0.186084826229\n",
      "\tacc: 0.925841584158\n",
      "\tauc: 0.974182662864\n",
      "\tap@k: 0.981137969662\n",
      "Epoch: 85\n",
      "Train:\n",
      "\tloss: 0.155840803835\n",
      "\tacc: 0.94198019802\n",
      "\tauc: 0.978925709788\n",
      "\tap@k: 0.998604575307\n",
      "Val:\n",
      "\tloss: 0.177465980146\n",
      "\tacc: 0.932574257426\n",
      "\tauc: 0.976433970758\n",
      "\tap@k: 0.993016728765\n",
      "Epoch: 86\n",
      "Train:\n",
      "\tloss: 0.149207772691\n",
      "\tacc: 0.944059405941\n",
      "\tauc: 0.979583209121\n",
      "\tap@k: 0.997328664234\n",
      "Val:\n",
      "\tloss: 0.180314100284\n",
      "\tacc: 0.931881188119\n",
      "\tauc: 0.97634875646\n",
      "\tap@k: 0.992771719794\n",
      "Epoch: 87\n",
      "Train:\n",
      "\tloss: 0.164556298159\n",
      "\tacc: 0.940297029703\n",
      "\tauc: 0.975318617468\n",
      "\tap@k: 0.994179687387\n",
      "Val:\n",
      "\tloss: 0.183482346517\n",
      "\tacc: 0.931089108911\n",
      "\tauc: 0.977324857507\n",
      "\tap@k: 0.997171990754\n",
      "Epoch: 88\n",
      "Train:\n",
      "\tloss: 0.146067903298\n",
      "\tacc: 0.946138613861\n",
      "\tauc: 0.980594043597\n",
      "\tap@k: 0.991362019378\n",
      "Val:\n",
      "\tloss: 0.169774549207\n",
      "\tacc: 0.930495049505\n",
      "\tauc: 0.979126783918\n",
      "\tap@k: 0.993188395988\n",
      "Epoch: 89\n",
      "Train:\n",
      "\tloss: 0.133964779325\n",
      "\tacc: 0.954752475248\n",
      "\tauc: 0.984198519133\n",
      "\tap@k: 0.990966038526\n",
      "Val:\n",
      "\tloss: 0.152218959467\n",
      "\tacc: 0.939504950495\n",
      "\tauc: 0.982465753382\n",
      "\tap@k: 0.996609209414\n",
      "Epoch: 90\n",
      "Train:\n",
      "\tloss: 0.125942318433\n",
      "\tacc: 0.953465346535\n",
      "\tauc: 0.985411864645\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.140085934692\n",
      "\tacc: 0.94504950495\n",
      "\tauc: 0.984286707096\n",
      "\tap@k: 0.993380963263\n",
      "Epoch: 91\n",
      "Train:\n",
      "\tloss: 0.122373660037\n",
      "\tacc: 0.954851485149\n",
      "\tauc: 0.985854995798\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.147939411527\n",
      "\tacc: 0.941881188119\n",
      "\tauc: 0.983318020248\n",
      "\tap@k: 0.985473299265\n",
      "Epoch: 92\n",
      "Train:\n",
      "\tloss: 0.109547476747\n",
      "\tacc: 0.960495049505\n",
      "\tauc: 0.988299644274\n",
      "\tap@k: 0.982550925535\n",
      "Val:\n",
      "\tloss: 0.140346105606\n",
      "\tacc: 0.947722772277\n",
      "\tauc: 0.984849045754\n",
      "\tap@k: 0.992286445148\n",
      "Epoch: 93\n",
      "Train:\n",
      "\tloss: 0.107756903835\n",
      "\tacc: 0.961881188119\n",
      "\tauc: 0.987774610355\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.145770985688\n",
      "\tacc: 0.943762376238\n",
      "\tauc: 0.982560745229\n",
      "\tap@k: 0.997343566844\n",
      "Epoch: 94\n",
      "Train:\n",
      "\tloss: 0.110651079792\n",
      "\tacc: 0.96\n",
      "\tauc: 0.987513248963\n",
      "\tap@k: 0.996303546962\n",
      "Val:\n",
      "\tloss: 0.128294040976\n",
      "\tacc: 0.95099009901\n",
      "\tauc: 0.98591285704\n",
      "\tap@k: 0.994590161136\n",
      "Epoch: 95\n",
      "Train:\n",
      "\tloss: 0.0961227931322\n",
      "\tacc: 0.964653465347\n",
      "\tauc: 0.989734013372\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.117746351292\n",
      "\tacc: 0.956138613861\n",
      "\tauc: 0.987318742487\n",
      "\tap@k: 0.992230044596\n",
      "Epoch: 96\n",
      "Train:\n",
      "\tloss: 0.0993435041577\n",
      "\tacc: 0.964257425743\n",
      "\tauc: 0.989114830768\n",
      "\tap@k: 0.992652027283\n",
      "Val:\n",
      "\tloss: 0.132868500143\n",
      "\tacc: 0.948811881188\n",
      "\tauc: 0.986399691669\n",
      "\tap@k: 1.0\n",
      "Epoch: 97\n",
      "Train:\n",
      "\tloss: 0.104761977538\n",
      "\tacc: 0.961881188119\n",
      "\tauc: 0.98938219181\n",
      "\tap@k: 0.98965426064\n",
      "Val:\n",
      "\tloss: 0.136048650926\n",
      "\tacc: 0.947920792079\n",
      "\tauc: 0.985520497948\n",
      "\tap@k: 1.0\n",
      "Epoch: 98\n",
      "Train:\n",
      "\tloss: 0.102581547243\n",
      "\tacc: 0.962178217822\n",
      "\tauc: 0.989064288444\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.136020598413\n",
      "\tacc: 0.949504950495\n",
      "\tauc: 0.984858543946\n",
      "\tap@k: 1.0\n",
      "Epoch: 99\n",
      "Train:\n",
      "\tloss: 0.0951857818541\n",
      "\tacc: 0.965247524752\n",
      "\tauc: 0.989897644632\n",
      "\tap@k: 1.0\n",
      "Val:\n",
      "\tloss: 0.12473220652\n",
      "\tacc: 0.95198019802\n",
      "\tauc: 0.986441435252\n",
      "\tap@k: 0.99623071423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 100\n",
    "minibatches_per_epoch = 100\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    print \"Epoch: {}\".format(i)\n",
    "    #training\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    \n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_tr,title_tr,nontext_tr,target_tr,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch:break\n",
    "            \n",
    "        loss,pred_probas = train_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "    \n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Train:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "    \n",
    "    #evaluation\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_ts,title_ts,nontext_tr,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch: break\n",
    "        loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "\n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Val:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "\tloss: 0.124100072199\n",
      "\tacc: 0.952295652174\n",
      "\tauc: 0.986636586364\n",
      "\tap@k: 0.99327600209\n",
      "\n",
      "AUC:\n",
      "\tОтличное решение! (good)\n",
      "\n",
      "Accuracy:\n",
      "\tОтличный результат! (good)\n",
      "\n",
      "Average precision at K:\n",
      "\tЗасабмить на kaggle! (great) \n",
      "\t Нет, ну честно - выкачай avito_test.tsv, засабмить и скажи, что вышло.\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "epoch_y_true = []\n",
    "epoch_y_pred = []\n",
    "\n",
    "b_c = b_loss = 0\n",
    "for j, (b_desc,b_title,b_cat, b_y) in enumerate(\n",
    "    iterate_minibatches(desc_ts,title_ts,nontext_tr,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "    loss,pred_probas = eval_fun(b_desc,b_title,b_cat,b_y)\n",
    "\n",
    "    b_loss += loss\n",
    "    b_c +=1\n",
    "\n",
    "    epoch_y_true.append(b_y)\n",
    "    epoch_y_pred.append(pred_probas)\n",
    "\n",
    "\n",
    "epoch_y_true = np.concatenate(epoch_y_true)\n",
    "epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "\n",
    "final_accuracy = accuracy_score(epoch_y_true,epoch_y_pred>0)\n",
    "final_auc = roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "final_apatk = APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "\n",
    "print \"Scores:\"\n",
    "print '\\tloss:',b_loss/b_c\n",
    "print '\\tacc:',final_accuracy\n",
    "print '\\tauc:',final_auc\n",
    "print '\\tap@k:',final_apatk\n",
    "score(final_accuracy,final_auc,final_apatk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main task\n",
    "\n",
    "* Feel like Le'Cun:\n",
    " * accuracy > 0.95\n",
    " * AUC > 0.97\n",
    " * Average Precision at (test sample size * 0.025) > 0.99\n",
    " * And perhaps even farther\n",
    "\n",
    "* Casual mode\n",
    " * accuracy > 0.90\n",
    " * AUC > 0.95\n",
    " * Average Precision at (test sample size * 0.025) > 0.92"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
